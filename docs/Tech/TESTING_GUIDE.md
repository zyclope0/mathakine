# Guide complet du systÃ¨me de tests - Mathakine

Ce document dÃ©crit l'architecture de test complÃ¨te du projet Mathakine, incluant la structure, les types de tests, l'exÃ©cution, le systÃ¨me CI/CD intÃ©grÃ© et les bonnes pratiques.

## 1. Vue d'ensemble du systÃ¨me de tests

Le projet Mathakine implÃ©mente une architecture de tests en 4 niveaux avec un systÃ¨me CI/CD intÃ©grÃ© pour assurer la qualitÃ© et la fiabilitÃ© du code. Cette approche permet de tester l'application sous diffÃ©rents angles, de l'unitÃ© individuelle jusqu'au systÃ¨me complet.

### Niveaux de tests

1. **Tests Unitaires** - Tests isolÃ©s de composants individuels
2. **Tests API** - Tests pour valider les endpoints REST
3. **Tests d'IntÃ©gration** - Tests des composants en interaction
4. **Tests Fonctionnels** - Tests du systÃ¨me complet, basÃ©s sur les cas d'utilisation

### SystÃ¨me CI/CD avec Classification Intelligente

Le projet utilise un systÃ¨me de classification des tests en 3 niveaux de criticitÃ© :

#### ğŸ”´ Tests Critiques (BLOQUANTS)
- **Impact** : Bloquent le commit et le dÃ©ploiement
- **Timeout** : 3 minutes maximum
- **Ã‰checs max** : 1 seul Ã©chec autorisÃ©
- **Contenu** : Tests fonctionnels, services core, authentification

#### ğŸŸ¡ Tests Importants (NON-BLOQUANTS)  
- **Impact** : Avertissement, commit autorisÃ©
- **Timeout** : 2 minutes maximum
- **Ã‰checs max** : 5 Ã©checs autorisÃ©s
- **Contenu** : Tests d'intÃ©gration, modÃ¨les, adaptateurs

#### ğŸŸ¢ Tests ComplÃ©mentaires (INFORMATIFS)
- **Impact** : Information seulement
- **Timeout** : 1 minute maximum
- **Ã‰checs max** : 10 Ã©checs autorisÃ©s
- **Contenu** : CLI, initialisation, fonctionnalitÃ©s secondaires

### Installation du SystÃ¨me CI/CD

```bash
# Installation des hooks Git
python scripts/setup_git_hooks.py

# VÃ©rification manuelle
python scripts/pre_commit_check.py

# Tests par catÃ©gorie
python -m pytest tests/functional/ -v      # Critiques
python -m pytest tests/integration/ -v     # Importants
python -m pytest tests/unit/test_cli.py -v # ComplÃ©mentaires
```

### Pipeline GitHub Actions

Le pipeline CI/CD s'exÃ©cute automatiquement et comprend :
1. **Tests Critiques** en parallÃ¨le (fail-fast)
2. **Tests Importants** si critiques passent
3. **Tests ComplÃ©mentaires** informatifs
4. **Analyse de couverture** de code
5. **VÃ©rifications qualitÃ©** (Black, Flake8, Bandit)
6. **GÃ©nÃ©ration de rapports** et artifacts

Pour plus de dÃ©tails, consultez le [Guide CI/CD complet](../CI_CD_GUIDE.md).

### Structure des fichiers

```
tests/
â”œâ”€â”€ unit/                   # Tests unitaires
â”‚   â”œâ”€â”€ test_models.py      # Tests des modÃ¨les de donnÃ©es
â”‚   â”œâ”€â”€ test_services.py    # Tests des services mÃ©tier
â”‚   â”œâ”€â”€ test_cascade_relationships.py  # Test des relations en cascade
â”‚   â””â”€â”€ test_utils.py       # Tests des utilitaires
â”œâ”€â”€ api/                    # Tests API
â”‚   â”œâ”€â”€ test_base_endpoints.py     # Tests des endpoints de base
â”‚   â”œâ”€â”€ test_exercise_endpoints.py # Tests des endpoints d'exercices
â”‚   â”œâ”€â”€ test_user_endpoints.py     # Tests des endpoints utilisateurs 
â”‚   â”œâ”€â”€ test_deletion_endpoints.py  # Tests des endpoints de suppression
â”‚   â””â”€â”€ test_challenge_endpoints.py # Tests des endpoints de dÃ©fis logiques
â”œâ”€â”€ integration/            # Tests d'intÃ©gration
â”‚   â”œâ”€â”€ test_user_exercise_flow.py  # Tests du flux utilisateur-exercice
â”‚   â””â”€â”€ test_cascade_deletion.py    # Tests de suppression en cascade
â”œâ”€â”€ functional/             # Tests fonctionnels
â”‚   â”œâ”€â”€ test_logic_challenge.py     # Tests des dÃ©fis logiques
â”‚   â”œâ”€â”€ test_enhanced_server.py     # Tests du serveur
â”‚   â””â”€â”€ test_starlette_cascade_deletion.py  # Tests de suppression via Starlette
â”œâ”€â”€ fixtures/               # Fixtures rÃ©utilisables
â”‚   â”œâ”€â”€ model_fixtures.py   # Instances de modÃ¨les pour les tests
â”‚   â””â”€â”€ db_fixtures.py      # Sessions de base de donnÃ©es pour les tests
â”œâ”€â”€ conftest.py             # Configuration centralisÃ©e de pytest
â”œâ”€â”€ run_tests.py            # Script principal d'exÃ©cution
â”œâ”€â”€ run_tests.bat           # Script batch pour Windows
â”œâ”€â”€ README.md               # Documentation des tests
â””â”€â”€ TEST_PLAN.md            # Plan de test dÃ©taillÃ©
```

## 2. Types de tests

### 2.1 Tests Unitaires (`unit/`)

Les tests unitaires vÃ©rifient le comportement des composants individuels en isolation.

#### Composants testÃ©s
- **ModÃ¨les de donnÃ©es** - crÃ©ation, validation, contraintes
- **Services mÃ©tier** - logique d'affaires
- **Utilitaires** - fonctions auxiliaires
- **Relations en cascade** - configuration des relations

#### Exemples implÃ©mentÃ©s
- `test_models.py` - Teste les modÃ¨les User, Exercise, Attempt, etc.
- `test_cascade_relationships.py` - VÃ©rifie les relations avec cascade="all, delete-orphan"
- `test_services.py` - Teste les services ExerciseService, UserService, etc.
- `test_enhanced_server_adapter.py` - Teste l'adaptateur pour le serveur Starlette

### 2.2 Tests API (`api/`)

Les tests API vÃ©rifient le comportement des endpoints REST, incluant les rÃ©ponses, les codes d'Ã©tat et la validation des donnÃ©es.

#### Endpoints testÃ©s
- **Endpoints de base** - racine, info, debug
- **Endpoints d'utilisateurs** - crÃ©ation, authentification, profil
- **Endpoints d'exercices** - liste, dÃ©tail, soumission, suppression
- **Endpoints de dÃ©fis logiques** - liste, dÃ©tail, rÃ©solution

#### Exemples implÃ©mentÃ©s
- `test_base_endpoints.py` - Teste les endpoints de base
- `test_exercise_endpoints.py` - Teste les endpoints d'exercices
- `test_deletion_endpoints.py` - Teste les suppressions en cascade via API

### 2.3 Tests d'IntÃ©gration (`integration/`)

Les tests d'intÃ©gration vÃ©rifient l'interaction entre plusieurs composants de l'application.

#### Flux testÃ©s
- **Flux utilisateur-exercice** - Inscription â†’ Exercice â†’ RÃ©ponse â†’ Statistiques
- **Suppression en cascade** - VÃ©rification de l'intÃ©gritÃ© rÃ©fÃ©rentielle
- **Transactions** - Comportement des transactions sur plusieurs tables

#### Exemples implÃ©mentÃ©s
- `test_user_exercise_flow.py` - Teste le flux complet utilisateur-exercice
- `test_cascade_deletion.py` - Teste la suppression en cascade entre modÃ¨les

### 2.4 Tests Fonctionnels (`functional/`)

Les tests fonctionnels vÃ©rifient le comportement de l'application complÃ¨te du point de vue de l'utilisateur.

#### FonctionnalitÃ©s testÃ©es
- **DÃ©fis logiques** - Workflow complet des dÃ©fis
- **DÃ©marrage du serveur** - VÃ©rification du dÃ©marrage correct
- **Suppressions en cascade** - Comportement end-to-end dans Starlette

#### Exemples implÃ©mentÃ©s
- `test_logic_challenge.py` - Teste les dÃ©fis logiques
- `test_enhanced_server.py` - Teste le dÃ©marrage du serveur
- `test_starlette_cascade_deletion.py` - Teste les suppressions dans le serveur

## 3. Focus sur les tests de suppression en cascade

Un ensemble spÃ©cifique de tests a Ã©tÃ© mis en place pour valider le mÃ©canisme de suppression en cascade, essentiel Ã  l'intÃ©gritÃ© des donnÃ©es.

### 3.1 Tests unitaires
- VÃ©rifient la configuration des relations avec `cascade="all, delete-orphan"`
- Test des relations entre User, Exercise, Attempt, LogicChallenge

### 3.2 Tests d'intÃ©gration
- Valident que la suppression d'une entitÃ© dÃ©clenche la suppression des entitÃ©s dÃ©pendantes
- Testent les suppressions pour User â†’ Exercise â†’ Attempt

### 3.3 Tests API
- VÃ©rifient les endpoints de suppression (DELETE /api/exercises/{id}, etc.)
- Testent les autorisations et les cas d'erreur

### 3.4 Tests fonctionnels
- Testent le comportement end-to-end dans le serveur Starlette
- VÃ©rifient l'intÃ©gritÃ© rÃ©fÃ©rentielle complÃ¨te

### Exemple de test de suppression en cascade

```python
def test_exercise_cascade_deletion(db_session):
    """Test that deleting an exercise cascades to attempts"""
    # CrÃ©er un utilisateur
    user = User(username="cascade_test", email="cascade@test.com", 
                hashed_password="hashed_pass")
    db_session.add(user)
    db_session.commit()
    
    # CrÃ©er un exercice
    exercise = Exercise(title="Cascade Test", creator_id=user.id,
                       exercise_type=ExerciseType.ADDITION,
                       difficulty=DifficultyLevel.INITIE,
                       question="1+1=?", correct_answer="2")
    db_session.add(exercise)
    db_session.commit()
    
    # CrÃ©er des tentatives
    attempt = Attempt(user_id=user.id, exercise_id=exercise.id,
                     user_answer="2", is_correct=True)
    db_session.add(attempt)
    db_session.commit()
    
    # VÃ©rifier que la tentative existe
    assert db_session.query(Attempt).filter_by(id=attempt.id).first() is not None
    
    # Supprimer l'exercice
    db_session.delete(exercise)
    db_session.commit()
    
    # VÃ©rifier que la tentative a Ã©tÃ© supprimÃ©e en cascade
    assert db_session.query(Attempt).filter_by(id=attempt.id).first() is None
```

## 4. Fixtures et configuration des tests

### 4.1 Fixtures rÃ©utilisables

Les fixtures sont centralisÃ©es dans le dossier `fixtures/` pour faciliter la rÃ©utilisation :

#### ModÃ¨les (`model_fixtures.py`)
- Fournit des instances prÃ©configurÃ©es des modÃ¨les
- Exemples : `test_user()`, `test_exercise()`, `test_logic_challenge()`

#### Base de donnÃ©es (`db_fixtures.py`)
- Fournit des sessions de base de donnÃ©es pour les tests
- Supporte SQLite et PostgreSQL
- Exemples : `db_session()`, `populated_db_session()`

### 4.2 Configuration centralisÃ©e

Le fichier `conftest.py` centralise la configuration de pytest :

- **Configuration de session** - Initialisation et nettoyage
- **Fixtures d'authentification** - Pour les tests nÃ©cessitant un utilisateur connectÃ©
- **Base de donnÃ©es temporaire** - Configuration automatique de la base de test

## 5. ExÃ©cution des tests

### 5.1 Script unifiÃ©

Le script `run_tests.bat` (Windows) ou `run_tests.py` (multiplateforme) permet d'exÃ©cuter les tests facilement :

```bash
# ExÃ©cuter tous les tests
tests/run_tests.bat --all

# ExÃ©cuter par catÃ©gorie
tests/run_tests.bat --unit      # Tests unitaires
tests/run_tests.bat --api       # Tests API
tests/run_tests.bat --integration # Tests d'intÃ©gration
tests/run_tests.bat --functional # Tests fonctionnels

# Options additionnelles
tests/run_tests.bat --file FILE  # Tester un fichier spÃ©cifique
tests/run_tests.bat --verbose    # Mode verbeux
tests/run_tests.bat --no-coverage # DÃ©sactiver la couverture
```

### 5.2 Via Python directement

Vous pouvez Ã©galement exÃ©cuter les tests directement avec pytest :

```bash
# Tous les tests
python -m pytest tests/

# Tests par dossier
python -m pytest tests/unit/
python -m pytest tests/api/
python -m pytest tests/integration/
python -m pytest tests/functional/

# Couverture de code
python -m pytest --cov=app --cov-report=html:test_results/coverage tests/
```

### 5.3 Base de donnÃ©es de test

Par dÃ©faut, les tests utilisent SQLite, mais vous pouvez configurer PostgreSQL :

```bash
# Windows
set TEST_DATABASE_URL=postgresql://user:password@localhost:5432/test_db
run_tests.bat --all

# Linux/Mac
export TEST_DATABASE_URL=postgresql://user:password@localhost:5432/test_db
./run_tests.sh --all
```

## 6. SystÃ¨me d'auto-validation

Le projet intÃ¨gre un systÃ¨me complet d'auto-validation pour vÃ©rifier l'intÃ©gritÃ© et la compatibilitÃ©.

### 6.1 Scripts principaux

| Script | Description |
|--------|-------------|
| `auto_validation.py` | Validation complÃ¨te du projet |
| `auto_validate.bat` | Script batch pour Windows |
| `simple_validation.py` | VÃ©rification simplifiÃ©e |
| `compatibility_check.py` | VÃ©rification de compatibilitÃ© |
| `generate_report.py` | GÃ©nÃ©ration de rapport |

### 6.2 Utilisation recommandÃ©e

#### Validation quotidienne
```bash
python tests/simplified_validation.py
```

#### Avant un commit
```bash
tests/auto_validate.bat
```

#### AprÃ¨s mise Ã  jour des dÃ©pendances
```bash
python tests/compatibility_check.py
```

## 7. Rapports et rÃ©sultats

Tous les rapports sont gÃ©nÃ©rÃ©s dans le dossier `test_results/` :

1. **Journal dÃ©taillÃ©** - `auto_validation_TIMESTAMP.log`
2. **Rapport de couverture** - `coverage/index.html`
3. **Rapport JUnit XML** - `junit.xml`
4. **Rapport complet** - `rapport_complet_TIMESTAMP.md`

### RÃ©sultats actuels (mai 2025)

- **58 tests rÃ©ussis**
- **1 test ignorÃ©** (PostgreSQL spÃ©cifique)
- **0 Ã©checs**
- **Couverture de code: 64%**
- **Temps d'exÃ©cution moyen: ~25 secondes**

## 8. Bonnes pratiques

### 8.1 Nommage des tests
- Utiliser des noms descriptifs (`test_user_deletion_cascades_to_exercises`)
- PrÃ©fixer avec `test_`
- Inclure le comportement attendu

### 8.2 Organisation
- Un fichier de test par module
- Tests indÃ©pendants
- Nettoyage aprÃ¨s chaque test

### 8.3 Assertions
- VÃ©rifier un comportement par test
- Utiliser des messages d'erreur clairs
- Tester les cas positifs et nÃ©gatifs

### 8.4 Fixtures
- RÃ©utiliser les fixtures centralisÃ©es
- Isoler les dÃ©pendances
- Nettoyer les ressources

## 9. Plan d'amÃ©lioration des tests

### 9.1 Couverture Ã  amÃ©liorer
- Services mÃ©tier (gÃ©nÃ©ration d'exercices, validation des rÃ©ponses)
- Cas d'erreur et cas limites
- Nouveaux endpoints

### 9.2 Tests Ã  ajouter
- Tests de performance
- Tests d'interface utilisateur
- Tests de dÃ©ploiement

### 9.3 Tests asynchrones
- Support amÃ©liorÃ© pour les fonctions asynchrones
- Tests de concurrence

## 10. CritÃ¨res de succÃ¨s

Pour valider la qualitÃ© des tests, nous nous basons sur les critÃ¨res suivants :

### 10.1 Couverture
- Unitaires : > 90%
- API : > 85%
- IntÃ©gration : > 80%
- Fonctionnels : > 75%

### 10.2 Performance
- Temps de rÃ©ponse < 200ms
- Utilisation CPU < 50%
- Utilisation mÃ©moire < 500MB

### 10.3 QualitÃ©
- Aucun test Ã©chouÃ©
- Aucune vulnÃ©rabilitÃ© critique
- Documentation Ã  jour

## 11. ResponsabilitÃ©s

| RÃ´le | ResponsabilitÃ© |
|------|----------------|
| DÃ©veloppeur | Tests unitaires et API |
| Testeur | Tests d'intÃ©gration et fonctionnels |
| Lead Dev | Supervision de la qualitÃ© |
| DevOps | Configuration de l'environnement |

## 12. DÃ©pannage courant

| ProblÃ¨me | Cause possible | Solution |
|----------|----------------|----------|
| Ã‰chec SQLAlchemy avec Python 3.13 | IncompatibilitÃ© | Utiliser Python 3.11/3.12 ou SQLAlchemy 2.0.27+ |
| Erreur d'importation | Module manquant | ExÃ©cuter `setup_validation.py` |
| ProblÃ¨mes de permissions | Droits insuffisants | ExÃ©cuter en administrateur |
| Tests bloquÃ©s | Processus en arriÃ¨re-plan | RedÃ©marrer le terminal |

---

*Ce document consolide les informations de tests/README.md, tests/TEST_PLAN.md et docs/TESTS.md* 