# üß™ TESTING GUIDE - MATHAKINE

**Version** : 3.1.0  
**Date** : 11 fevrier 2026 (mise a jour)  
**Audience** : Developpeurs, QA

---

## üìã TABLE DES MATI√àRES

1. [Vue d'ensemble](#vue-ensemble)
2. [Configuration tests](#configuration)
3. [Tests backend](#tests-backend)
4. [Tests frontend](#tests-frontend)
5. [Plan de test manuel ‚Äî Environnement dev](#plan-test-manuel-dev)
6. [CI/CD](#cicd)
7. [Best practices](#best-practices)
8. [Modifications recentes](#modifications-recentes)

---

## üéØ VUE D'ENSEMBLE {#vue-ensemble}

### Strat√©gie de tests

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ        Tests Pyramide                    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ              E2E (5%)                    ‚îÇ
‚îÇ          ‚ñ≤  Playwright                   ‚îÇ
‚îÇ         ‚îÇ‚îÇ                               ‚îÇ
‚îÇ       Integration (25%)                  ‚îÇ
‚îÇ      ‚ñ≤  pytest + httpx.AsyncClient       ‚îÇ
‚îÇ     ‚îÇ‚îÇ                                   ‚îÇ
‚îÇ   Unit Tests (70%)                       ‚îÇ
‚îÇ  ‚ñ≤  pytest + Vitest                      ‚îÇ
‚îÇ ‚îÇ‚îÇ                                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

> **Migration 08/02/2026** : Les tests backend ont ete migres de `starlette.testclient.TestClient` (sync) vers `httpx.AsyncClient` (async natif Starlette). Tous les tests d'integration utilisent desormais `pytest-asyncio`.

### Objectifs coverage
- **Unit tests** : 80%+ (objectif long terme)
- **Integration tests** : 60%+
- **E2E tests** : Scenarios critiques
- **Global coverage** : 70%+

> **Strategie actuelle** : Augmenter progressivement plutot qu'en bloc. Pour chaque nouvelle feature importante, ajouter 1-2 tests. Passer a une phase de mont√©e en couverture quand les features sont stabilisees.

### Tests actuels (25/02/2026)
- ‚úÖ **Backend** : ~443 tests passent, skippes r√©duits, ~48% couverture (app + server)
- ‚úÖ **Frontend** : 37 tests (Vitest), utils/lib validations + composants + hooks (dont QuickStartActions analytics)
- ‚úÖ **CI** : Tests + couverture backend et frontend, upload Codecov (flags backend/frontend)
- ‚úÖ **Tests critiques** : auth, challenges, exercises, user_exercise_flow, admin analytics EdTech
- ‚úÖ **Base de test separee** : `TEST_DATABASE_URL` obligatoire (protection production)
- ‚úÖ **Tests async** : httpx.AsyncClient + pytest-asyncio (Starlette natif)

---

## ‚öôÔ∏è CONFIGURATION TESTS {#configuration}

### Backend (pytest)

#### Commande unique (recommand√©)
```bash
make test-backend-local
```
ou sans Make : `python scripts/test_backend_local.py` ‚Äî d√©marre PostgreSQL (Docker si absent), init DB, pytest.

#### Quick start manuel avec Docker
> **Connection refused localhost:5432 ?** ‚Äî Les tests backend n√©cessitent PostgreSQL. Avec Docker :

```bash
# 1. D√©marrer PostgreSQL (postgres:15, port 5432)
docker run -d --name pg-mathakine -e POSTGRES_PASSWORD=postgres -p 5432:5432 postgres:15

# 2. Pr√©parer la base de test (cr√©e la base + migrations + donn√©es de test)
python scripts/check_local_db.py

# 3. Lancer les tests
python -m pytest tests/ -q -m "not slow"
```

Voir [CREATE_TEST_DATABASE.md](CREATE_TEST_DATABASE.md) pour plus d‚Äôoptions. Alternative tout-en-un : `make test-backend-local`.

#### Pr√©requis
> **Important** : Les tests backend n√©cessitent l'installation compl√®te des d√©pendances.
> Sans `python-dotenv` (chargement du `.env`), `pytest` √©chouera au d√©marrage.
```bash
pip install -r requirements.txt
```

#### Installation minimale (CI, variables d√©j√† d√©finies)
```bash
pip install pytest pytest-cov pytest-asyncio httpx python-dotenv
```

#### pytest.ini
```ini
[pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*

addopts =
    -v
    --strict-markers
    --tb=short
    --cov=app
    --cov=server
    --cov-report=term-missing
    --cov-report=html
    --cov-report=xml

markers =
    slow: marks tests as slow
    integration: marks tests as integration tests
    unit: marks tests as unit tests
    api: marks tests as API tests
    critical: marks tests as critical paths
```

#### conftest.py

**‚ö†Ô∏è IMPORTANT** : Les tests utilisent `TEST_DATABASE_URL` (PostgreSQL) et `httpx.AsyncClient`. Voir [CREATE_TEST_DATABASE.md](CREATE_TEST_DATABASE.md) pour la configuration.

```python
# tests/conftest.py (simplifie - voir le fichier reel pour la version complete)
import pytest
import os
from httpx import AsyncClient, ASGITransport
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

from app.db.base import Base
from server.app import create_app

# Database de test - DOIT etre definie dans l'environnement
TEST_DATABASE_URL = os.getenv("TEST_DATABASE_URL")
if not TEST_DATABASE_URL:
    raise Exception("TEST_DATABASE_URL doit etre definie pour executer les tests")

@pytest.fixture(scope="session")
def engine():
    """Engine SQLAlchemy pour tests"""
    engine = create_engine(TEST_DATABASE_URL, pool_pre_ping=True)
    Base.metadata.create_all(bind=engine)
    yield engine
    Base.metadata.drop_all(bind=engine)

@pytest.fixture(scope="function")
def db(engine):
    """Session DB pour chaque test"""
    TestingSessionLocal = sessionmaker(bind=engine)
    session = TestingSessionLocal()
    yield session
    session.rollback()
    session.close()

@pytest.fixture(scope="module")
async def client():
    """Client de test async (httpx.AsyncClient)"""
    app = create_app()
    transport = ASGITransport(app=app)
    async with AsyncClient(transport=transport, base_url="http://test") as ac:
        yield ac

@pytest.fixture
def sample_user(db):
    """Utilisateur de test"""
    from app.models.user import User
    user = User(
        username="testuser",
        email="test@example.com",
        hashed_password="hashed_password",
        role="student"
    )
    db.add(user)
    db.commit()
    db.refresh(user)
    return user
```

> **Note** : Le `conftest.py` reel inclut egalement des safeguards pour empecher toute operation destructive sur la base de production (filtrage des DELETE/TRUNCATE, warnings si `TEST_DATABASE_URL` n'est pas defini).

### Frontend (Vitest + React Testing Library)

#### Installation
```bash
cd frontend
npm ci  # inclut vitest, @testing-library/react, @testing-library/user-event, @vitest/coverage-v8
```

#### vitest.config.ts
```typescript
// frontend/vitest.config.ts
export default defineConfig({
  test: {
    globals: true,
    environment: 'jsdom',
    setupFiles: ['./vitest.setup.ts'],
    coverage: {
      provider: 'v8',
      reporter: ['text', 'json', 'html', 'lcov'],
      exclude: ['**/__tests__/**', '**/*.config.*', '**/types/**'],
    },
  },
  resolve: { alias: { '@': path.resolve(__dirname, './') } },
});
```

---

## üêç TESTS BACKEND {#tests-backend}

### Tests unitaires

#### Service tests
```python
# tests/unit/test_logic_challenge_service.py
import pytest
from app.models.logic_challenge import LogicChallenge, LogicChallengeType, AgeGroup
from app.services.logic_challenge_service import LogicChallengeService

@pytest.mark.unit
def test_get_challenge(db_session):
    """Test r√©cup√©ration d'un d√©fi logique par ID"""
    challenge = LogicChallenge(
        title="Test Get Challenge",
        description="Un d√©fi de test",
        challenge_type="SEQUENCE",
        age_group="GROUP_10_12",
        correct_answer="42",
        solution_explanation="Explication",
        difficulty_rating=3.0,
    )
    db_session.add(challenge)
    db_session.commit()

    result = LogicChallengeService.get_challenge(db_session, challenge.id)

    assert result is not None
    assert result.id == challenge.id
    assert result.title == "Test Get Challenge"

@pytest.mark.unit
def test_list_challenges(db_session):
    """Test liste des d√©fis logiques"""
    results = LogicChallengeService.list_challenges(db_session, limit=10)

    assert isinstance(results, list)
    assert all(hasattr(c, "title") and hasattr(c, "challenge_type") for c in results)
```

#### Constants tests
```python
# tests/unit/test_constants.py
import pytest
from app.core.constants import (
    normalize_challenge_type,
    normalize_age_group,
    CHALLENGE_TYPES_DB,
    AGE_GROUPS_DB
)

@pytest.mark.unit
class TestNormalization:
    """Tests des fonctions de normalisation"""
    
    def test_normalize_challenge_type_lowercase(self):
        """Test normalisation type minuscule"""
        assert normalize_challenge_type("sequence") == "SEQUENCE"
        assert normalize_challenge_type("pattern") == "PATTERN"
    
    def test_normalize_challenge_type_uppercase(self):
        """Test normalisation type majuscule"""
        assert normalize_challenge_type("SEQUENCE") == "SEQUENCE"
    
    def test_normalize_challenge_type_invalid(self):
        """Test normalisation type invalide"""
        with pytest.raises(ValueError):
            normalize_challenge_type("invalid_type")
    
    def test_normalize_age_group(self):
        """Test normalisation groupe d'√¢ge"""
        assert normalize_age_group("age_6_8") == "GROUP_6_8"
        assert normalize_age_group("GROUP_10_12") == "GROUP_10_12"
```

### Tests d'int√©gration

#### API tests
```python
# tests/api/test_challenges_flow.py
import pytest

@pytest.mark.api
@pytest.mark.critical
class TestChallengesFlow:
    """Tests du flow complet challenges"""
    
    def test_list_challenges(self, client, auth_headers):
        """Test GET /api/challenges"""
        response = client.get(
            "/api/challenges",
            headers=auth_headers
        )
        
        assert response.status_code == 200
        data = response.json()
        assert isinstance(data, list)
    
    def test_get_challenge_details(self, client, sample_challenge, auth_headers):
        """Test GET /api/challenges/{id}"""
        response = client.get(
            f"/api/challenges/{sample_challenge.id}",
            headers=auth_headers
        )
        
        assert response.status_code == 200
        data = response.json()
        assert data["id"] == sample_challenge.id
        assert "title" in data
        assert "challenge_type" in data
    
    def test_submit_challenge_attempt_correct(self, client, sample_challenge, auth_headers):
        """Test POST /api/challenges/{id}/attempt - r√©ponse correcte"""
        response = client.post(
            f"/api/challenges/{sample_challenge.id}/attempt",
            json={"user_answer": sample_challenge.correct_answer},
            headers=auth_headers
        )
        
        assert response.status_code == 200
        data = response.json()
        assert data["is_correct"] is True
        assert "points_earned" in data
    
    def test_submit_challenge_attempt_incorrect(self, client, sample_challenge, auth_headers):
        """Test POST /api/challenges/{id}/attempt - r√©ponse incorrecte"""
        response = client.post(
            f"/api/challenges/{sample_challenge.id}/attempt",
            json={"user_answer": "wrong_answer"},
            headers=auth_headers
        )
        
        assert response.status_code == 200
        data = response.json()
        assert data["is_correct"] is False
    
    def test_challenges_filters(self, client, auth_headers):
        """Test filtres challenges"""
        response = client.get(
            "/api/challenges?challenge_type=SEQUENCE&age_group=GROUP_10_12",
            headers=auth_headers
        )
        
        assert response.status_code == 200
        data = response.json()
        
        for challenge in data:
            assert challenge["challenge_type"] == "SEQUENCE"
            assert challenge["age_group"] == "GROUP_10_12"
```

#### Auth flow tests
```python
# tests/api/test_auth_flow.py
import pytest

@pytest.mark.api
@pytest.mark.critical
class TestAuthFlow:
    """Tests du flow d'authentification"""
    
    def test_login_success(self, client, sample_user):
        """Test connexion r√©ussie"""
        response = client.post("/api/auth/login", json={
            "username": "testuser",
            "password": "testpassword"
        })
        
        assert response.status_code == 200
        data = response.json()
        assert "access_token" in data
        assert data["token_type"] == "bearer"
        assert "user" in data
    
    def test_login_invalid_credentials(self, client):
        """Test connexion avec mauvais credentials"""
        response = client.post("/api/auth/login", json={
            "username": "invalid",
            "password": "wrong"
        })
        
        assert response.status_code == 401
    
    def test_get_current_user(self, client, auth_headers):
        """Test GET /api/users/me"""
        response = client.get(
            "/api/users/me",
            headers=auth_headers
        )
        
        assert response.status_code == 200
        data = response.json()
        assert "id" in data
        assert "username" in data
        assert "email" in data
    
    def test_refresh_token(self, client, refresh_token):
        """Test POST /api/auth/refresh"""
        response = client.post("/api/auth/refresh", json={
            "refresh_token": refresh_token
        })
        
        assert response.status_code == 200
        data = response.json()
        assert "access_token" in data
```

### Lancer les tests

```bash
# Tous les tests
pytest tests/ -v

# Tests unitaires uniquement (services, logique, unicit√© routes)
pytest tests/unit/ -v

# Tests API / integration uniquement
pytest tests/api/ tests/integration/ tests/functional/ -v

# Tests critiques uniquement
pytest tests/ -v -m critical

# Tests avec coverage
pytest tests/ -v --cov --cov-report=html

# Test sp√©cifique
pytest tests/api/test_auth_flow.py::TestAuthFlow::test_login_success -v

# Tests en parall√®le (plus rapide)
pytest tests/ -v -n auto
```

---

## ‚öõÔ∏è TESTS FRONTEND {#tests-frontend}

### Composants avec contexte (NextIntl, React Query)

Pour les composants utilisant `useTranslations` ou `useCompletedExercises`, fournir les providers :

```typescript
// frontend/__tests__/unit/components/ExerciseCard.test.tsx
import { NextIntlClientProvider } from 'next-intl';
import { QueryClient, QueryClientProvider } from '@tanstack/react-query';
import fr from '@/messages/fr.json';

vi.mock('@/hooks/useCompletedItems', () => ({
  useCompletedExercises: () => ({ isCompleted: () => false }),
}));

function TestWrapper({ children }: { children: React.ReactNode }) {
  return (
    <NextIntlClientProvider locale="fr" messages={fr}>
      <QueryClientProvider client={new QueryClient({ defaultOptions: { queries: { retry: false } } })}>
        {children}
      </QueryClientProvider>
    </NextIntlClientProvider>
  );
}

it('affiche le titre', () => {
  render(<ExerciseCard exercise={mockExercise} />, { wrapper: TestWrapper });
  expect(screen.getByText('Test Exercise')).toBeInTheDocument();
});
```

### Composants avec menu d√©roulant (userEvent)

Pour les composants dont le contenu est dans un popover/menu ferm√© par d√©faut (ex. AccessibilityToolbar) :

```typescript
import userEvent from '@testing-library/user-event';

it('affiche les options apr√®s ouverture du menu', async () => {
  render(<AccessibilityToolbar />);
  await userEvent.click(screen.getByRole('button', { name: /options d'accessibilit√©/i }));
  expect(screen.getByRole('switch', { name: /contraste √©lev√©/i })).toBeInTheDocument();
});
```

### Tests composants (exemple simple)

```typescript
// frontend/__tests__/unit/components/BadgeCard.test.tsx
import { render, screen } from '@testing-library/react';
import { BadgeCard } from '@/components/badges/BadgeCard';

describe('BadgeCard', () => {
  it('affiche le nom du badge', () => {
    render(<BadgeCard badge={mockBadge} isEarned={false} />);
    expect(screen.getByText('Premiers Pas')).toBeInTheDocument();
  });
});
```

### Tests hooks

```typescript
// frontend/__tests__/unit/hooks/useAccessibleAnimation.test.ts
import { renderHook } from '@testing-library/react';
import { useAccessibleAnimation } from '@/lib/hooks/useAccessibleAnimation';

describe('useAccessibleAnimation', () => {
  it('retourne des variants et transition', () => {
    const { result } = renderHook(() => useAccessibleAnimation());
    expect(result.current.createVariants).toBeDefined();
    expect(result.current.shouldReduceMotion).toBe(false);
  });
});
```

### Tests E2E (Playwright)

```typescript
// frontend/__tests__/e2e/auth.spec.ts
import { test, expect } from '@playwright/test';

test.describe('Authentication', () => {
  test('user can login successfully', async ({ page }) => {
    await page.goto('http://localhost:3000/login');
    await page.fill('[name="username"]', 'testuser');
    await page.fill('[name="password"]', 'testpassword');
    await page.click('[type="submit"]');
    await expect(page).toHaveURL(/dashboard/);
  });
});
```

### Lancer les tests

```bash
cd frontend

# Tests unitaires (Vitest)
npm run test

# Tests avec coverage
npm run test:coverage

# Tests en mode watch
npm run test -- --watch

# Interface UI interactive
npm run test:ui

# Tests E2E (Playwright)
npm run test:e2e
npm run test:e2e:ui
```

---

### Plan de test manuel ‚Äî Environnement dev {#plan-test-manuel-dev}

> Checklist pour valider l‚Äôinterface manuellement en local. Backend et frontend doivent √™tre d√©marr√©s (`make dev` ou `python enhanced_server.py` + `cd frontend && npm run dev`).

#### Pr√©-requis

| √âtape | Action | R√©sultat attendu |
|-------|--------|------------------|
| 1 | D√©marrer le backend | Serveur √©coute (ex. port 8000) |
| 2 | D√©marrer le frontend | App Next.js sur http://localhost:3000 |
| 3 | Cr√©er ou se connecter avec un compte test | Authentification OK, redirection vers `/dashboard` ou `/onboarding` |

---

#### Profil (`/profile`)

| √âtape | Action | R√©sultat attendu |
|-------|--------|------------------|
| 1 | Acc√©der √† `/profile` (menu utilisateur ‚Üí Profil) | Infos personnelles affich√©es (username, email masqu√©, tranche d‚Äô√¢ge, th√®me) |
| 2 | Onglet ¬´ Infos personnelles ¬ª : modifier nom affich√© (display_name) ‚Üí Enregistrer | Toast succ√®s, donn√©es mises √† jour |
| 3 | Onglet ¬´ Pr√©f√©rences d‚Äôapprentissage ¬ª : modifier tranche d‚Äô√¢ge ‚Üí Enregistrer | Toast succ√®s, pr√©f√©rences enregistr√©es |
| 4 | Onglet ¬´ S√©curit√© ¬ª : ouvrir le formulaire de changement de mot de passe | Formulaire affich√© (mot de passe actuel, nouveau, confirmation) |
| 5 | Changer le mot de passe avec valeurs valides | Toast succ√®s, d√©connexion puis reconnexion avec nouveau MDP |
| 6 | Changer le mot de passe avec mauvais mot de passe actuel | Erreur affich√©e, MDP inchang√© |

---

#### Param√®tres et suppression de compte (`/settings`)

| √âtape | Action | R√©sultat attendu |
|-------|--------|------------------|
| 1 | Acc√©der √† `/settings` | Langue, notifications, confidentialit√©, donn√©es, sessions, zone de suppression visibles |
| 2 | Modifier une pr√©f√©rence (ex. langue) ‚Üí Enregistrer | Toast succ√®s |
| 3 | Onglet ¬´ Sessions actives ¬ª : v√©rifier la liste | Sessions actuelles affich√©es (appareil, date, etc.) |
| 4 | R√©vocation d‚Äôune session autre que la courante | Session retir√©e de la liste (ou erreur explicite si non support√©) |
| 5 | Compte v√©rifi√© : cliquer ¬´ Supprimer mon compte ¬ª ‚Üí confirmer | Redirection vers `/`, compte supprim√©, d√©connexion |
| 6 | Compte non v√©rifi√© : supprimer le compte | Idem ‚Äî suppression possible (RGPD) sans v√©rification pr√©alable |

---

#### Classement (`/leaderboard`)

| √âtape | Action | R√©sultat attendu |
|-------|--------|------------------|
| 1 | Acc√©der √† `/leaderboard` (ou widget dashboard ‚Üí lien) | Liste des utilisateurs avec rangs, points, niveaux |
| 2 | Filtrer par tranche d‚Äô√¢ge (ex. 8‚Äì10 ans) | Classement filtr√© selon la tranche |
| 3 | Filtrer ¬´ Tous les √¢ges ¬ª | Retour au classement global |

---

#### Progression et Dashboard (`/dashboard`)

| √âtape | Action | R√©sultat attendu |
|-------|--------|------------------|
| 1 | Acc√©der √† `/dashboard` | Stats (exercices, d√©fis, niveau), graphiques, recommandations |
| 2 | Changer la plage temporelle (7j, 30j, 90j) | Donn√©es mises √† jour |
| 3 | V√©rifier le widget ¬´ Progression des d√©fis ¬ª | Nb compl√©t√©s, progression par type affich√©e |
| 4 | V√©rifier le widget ¬´ Recommandations ¬ª | Exercices/d√©fis sugg√©r√©s avec liens cliquables |
| 5 | Acc√©der √† `/badges` | Badges d√©bloqu√©s et non d√©bloqu√©s affich√©s |

---

#### Exercices (`/exercises`, `/exercises/[id]`)

| √âtape | Action | R√©sultat attendu |
|-------|--------|------------------|
| 1 | Acc√©der √† `/exercises` | Liste d‚Äôexercices avec cards |
| 2 | Filtrer par type (ex. calcul, g√©om√©trie) | Liste filtr√©e |
| 3 | Filtrer par tranche d‚Äô√¢ge | Liste filtr√©e |
| 4 | Activer ¬´ Masquer les compl√©t√©s ¬ª | Exercices compl√©t√©s masqu√©s |
| 5 | Recherche texte | R√©sultats filtr√©s (si impl√©ment√© c√¥t√© API) |
| 6 | Paginer (page 2) | Nouveaux exercices affich√©s |
| 7 | Cliquer sur un exercice ‚Üí ouvrir `/exercises/[id]` | Page de r√©solution charg√©e |
| 8 | Soumettre une r√©ponse correcte | Feedback succ√®s, progression mise √† jour |
| 9 | Soumettre une r√©ponse incorrecte | Feedback erreur, possibilit√© de r√©essayer |
| 10 | Retour √† la liste | Progression et stats actualis√©es (badge compl√©t√© si applicable) |

---

#### D√©fis (`/challenges`, `/challenge/[id]`)

| √âtape | Action | R√©sultat attendu |
|-------|--------|------------------|
| 1 | Acc√©der √† `/challenges` | Liste de d√©fis avec cards |
| 2 | Filtrer par type, tranche d‚Äô√¢ge, masquer compl√©t√©s | Liste filtr√©e |
| 3 | Paginer | Nouveaux d√©fis affich√©s |
| 4 | Cliquer sur un d√©fi ‚Üí ouvrir `/challenge/[id]` | Page de r√©solution charg√©e |
| 5 | R√©soudre un d√©fi (selon type : logique, visuel, etc.) | Feedback et mise √† jour progression |
| 6 | Retour liste | Progression des d√©fis coh√©rente avec le dashboard |

---

#### Recommandations

| √âtape | Action | R√©sultat attendu |
|-------|--------|------------------|
| 1 | Sur le dashboard : afficher le widget Recommandations | Exercices et/ou d√©fis sugg√©r√©s |
| 2 | Cliquer sur une recommandation (exercice) | Redirection vers `/exercises/[id]` |
| 3 | Cliquer sur une recommandation (d√©fi) | Redirection vers `/challenge/[id]` |

---

#### Utilisateur non v√©rifi√©

| √âtape | Action | R√©sultat attendu |
|-------|--------|------------------|
| 1 | Se connecter avec un compte non v√©rifi√© | Banni√®re ¬´ V√©rifiez votre email ¬ª affich√©e |
| 2 | Acc√©der √† `/profile` | Profil affich√© (lecture, √©dition limit√©e selon impl√©mentation) |
| 3 | Acc√©der √† `/settings` ‚Üí Supprimer mon compte | Compte supprim√© sans v√©rification pr√©alable |

---

### Priorit√©s de couverture frontend {#priorites-couverture}

> **Contexte** (audit 20/02/2026) : Les tests unitaires passent mais couvrent un sous-ensemble r√©duit (~4 fichiers vs ~120+ modules). Strat√©gie pragmatique : prioriser par impact sans complexifier.

#### Priorit√© 1 ‚Äî Utils et validations (effort faible)

Fonctions pures, peu de mocks, faciles √† maintenir.

| Cible | Fichier | Cas test√©s |
|-------|---------|------------|
| `safeValidateUserStats` | `lib/validations/dashboard.ts` | null/undefined, level (objet/number), progress_over_time, exercises_by_day |
| `extractShapeChoicesFromVisualData` | `lib/utils/visualChallengeUtils.ts` | shapes, layout, formats mixtes |

#### Priorit√© 2 ‚Äî R√©gression sur bugs corrig√©s

√Ä chaque correction de bug significative : ajouter un test minimal pour √©viter le retour.

#### Priorit√© 3 ‚Äî Hooks m√©tier (effort moyen)

Hooks avec logique r√©utilisable : `usePaginatedContent`, logique de filtre, etc.

#### √Ä √©viter pour l'instant

- Couvrir toutes les pages (trop de mocks : API, router, i18n, stores)
- Tester des composants purement pr√©sentationnels sans logique
- Tests trop coupl√©s √† l‚Äôimpl√©mentation

#### Corrections appliqu√©es (15/02/2026) ‚Äî tests ajout√©s

| Zone modifi√©e | Test ajout√© |
|---------------|-------------|
| `safeValidateUserStats` (typage level, progress_over_time, exercises_by_day) | `__tests__/unit/lib/validations/dashboard.test.ts` |

---

## üîÑ CI/CD {#cicd}

### Contexte BDD test / prod (refactor 22/02/2026)

| Environnement | Base de donn√©es | Initialisation |
|---------------|-----------------|----------------|
| **CI (GitHub Actions)** | `test_mathakine` (PostgreSQL 15) | Sch√©ma uniquement (`create_tables`). Pas de seed ObiWan. Tests isol√©s via fixtures. |
| **D√©veloppement local (Docker)** | `test_mathakine` ou similaire | Optionnel : `create_tables_with_test_data()` pour seed de d√©mo (scripts). |
| **Production** | Base d√©di√©e prod | Jamais de seed. Migrations Alembic uniquement. |

> **Important** : La BDD prod est totalement isol√©e. Le refactor CI (suppression du seed global) n'impacte que l'environnement de test. Risque minimal.

### GitHub Actions Workflow (.github/workflows/tests.yml)

| Job | Actions |
|-----|---------|
| **test** | PostgreSQL 15, schema init uniquement (sans seed), pytest (unit+api+integration), coverage + JUnit XML, upload Codecov (coverage + test_results, flag backend) |
| **lint** | flake8, black, isort, mypy (backend) |
| **frontend** | npm ci, tsc --noEmit, ESLint, vitest --coverage --reporter=junit, upload Codecov (coverage + test_results, flag frontend), build |

Un echec de test ou de lint bloque le merge. Les rapports de couverture sont envoyes a Codecov (backend + frontend separes).

### Test d'unicite des routes (15/02/2026)

Le fichier `tests/unit/test_routes_uniqueness.py` verifie qu'aucune route API ne partage le meme couple (method, path). Une collision provoquerait un routage errone vers Starlette. Le test parcourt `get_routes()` (Route + Mount) et echoue si un doublon est detecte.

**Configuration couverture :**
- `.coveragerc` ‚Äî sources (app, server), `relative_files=True` (chemins relatifs pour Codecov CI), exclusions, rapport XML
- **Codecov** : ajouter `CODECOV_TOKEN` dans GitHub Secrets. Installer l'[app Codecov](https://github.com/apps/codecov) pour le badge (sinon GitHub affiche "unknown").

---

## üìå R√àGLE PROJET : TESTS SYST√âMATIQUES {#regle-tests}

> **√Ä chaque nouvelle fonctionnalit√©, impl√©mentation ou correction** : challenger syst√©matiquement la pertinence de cr√©er ou mettre √† jour un test.
>
> - **Nouvelle fonctionnalit√©** ‚Üí envisager 1+ tests (unitaire ou int√©gration selon le p√©rim√®tre)
> - **Nouvelle impl√©mentation** (service, handler, utilitaire) ‚Üí au minimum 1 test de non-r√©gression
> - **Correction de bug** ‚Üí ajouter un test qui aurait d√©tect√© le bug (test de r√©gression)
>
> Si le test n‚Äôest pas pertinent (ex. changement cosm√©tique, config), le documenter bri√®vement dans le commit.

**R√©f√©rences :**
- Plan 4.1 (random_offset challenge_service) : [AUDIT_BACKEND ¬ß Plan 4.1](../03-PROJECT/AUDIT_BACKEND_INDUSTRIALISATION_2026-02.md#plan-41-√†-100--random_offset-challenge_service)

---

## ‚úÖ BEST PRACTICES {#best-practices}

### G√©n√©ral

1. **Tests avant code** (TDD)
```python
# 1. √âcrire le test (fail)
def test_calculate_score():
    assert calculate_score(user_id=1) == 85.5

# 2. √âcrire le code (pass)
def calculate_score(user_id: int) -> float:
    # Implementation
    return 85.5

# 3. Refactor
```

2. **AAA Pattern**
```python
def test_something():
    # Arrange - Pr√©parer
    user = create_test_user()
    
    # Act - Agir
    result = service.do_something(user)
    
    # Assert - V√©rifier
    assert result == expected_value
```

3. **Tests isol√©s**
```python
# ‚úÖ CORRECT - Chaque test est ind√©pendant
def test_create_user(db):
    user = create_user(db, "testuser")
    assert user.username == "testuser"

def test_update_user(db):
    user = create_user(db, "testuser")  # Cr√©er ici
    updated = update_user(db, user.id, "newname")
    assert updated.username == "newname"

# ‚ùå INCORRECT - Tests d√©pendants
def test_create_then_update(db):
    user = create_user(db, "testuser")
    updated = update_user(db, user.id, "newname")
    # Trop de choses test√©es en m√™me temps
```

4. **Noms explicites**
```python
# ‚úÖ CORRECT
def test_login_with_invalid_credentials_returns_401():
    pass

# ‚ùå INCORRECT
def test_login():
    pass
```

5. **Utiliser fixtures**
```python
@pytest.fixture
def authenticated_client(client, sample_user):
    """Client avec authentification"""
    token = create_access_token(sample_user.id)
    client.headers = {"Authorization": f"Bearer {token}"}
    return client

def test_protected_route(authenticated_client):
    response = authenticated_client.get("/api/protected")
    assert response.status_code == 200
```

6. **Mocker externes**
```python
from unittest.mock import patch, MagicMock

@patch('app.services.openai_service.OpenAI')
def test_ai_generation(mock_openai, db):
    """Test g√©n√©ration IA sans appeler vraiment l'API"""
    # Mock la r√©ponse
    mock_openai.return_value.chat.completions.create.return_value = MagicMock(
        choices=[MagicMock(message=MagicMock(content="Generated content"))]
    )
    
    # Tester
    result = generate_challenge_with_ai(db, "SEQUENCE", "MEDIUM")
    assert result.title == "Generated content"
```

---

## üßπ GESTION DES DONNEES DE TEST {#test-data}

### Utilisateurs permanents (JAMAIS supprimes)

Les utilisateurs suivants sont des comptes de demonstration ou de seed. Ils ne doivent **JAMAIS** etre supprimes, modifies ou impactes par les tests :

| Username | Role | Description |
|----------|------|-------------|
| `ObiWan` | Demonstration | Utilisateur de demo visible sur le dashboard |
| `maitre_yoda` | Maitre | Utilisateur seed pour la creation d'exercices |
| `padawan1` | Padawan | Utilisateur seed eleve |
| `gardien1` | Gardien | Utilisateur seed administrateur |

> **REGLE ABSOLUE** : Aucun test ne doit cr√©er de donn√©es (attempts, progress, recommendations) au nom de ces utilisateurs. Aucun `delete()` sans `.filter()` n'est autorise sur les tables partagees (attempts, progress, exercises, users).

### Conventions de nommage des donnees de test

Tous les tests doivent utiliser des noms qui correspondent aux patterns de nettoyage automatique :

**Usernames** (prefixes acceptes) :
```
test_%, new_test_%, duplicate_%, cascade_%, creator_%, service_%,
auth_test_%, isolated_%, flow_%, jedi_%, login_test_%, cascade_test_%
```

**Emails** (domaines de test) :
```
*@test.com, *@jedi.com, *@test.example.com, *@example.com
```

**Titres d'exercices** :
```
%test%, %Test%, %TEST%, Cascade %, Dashboard %
```

**Titres de defis** :
```
%test%, %Test%, %TEST%, D√©fi Auto-%, Nouveau d√©fi%
```

### Nettoyage automatique (TestDataManager)

Le nettoyage s'execute automatiquement apres chaque test via la fixture `auto_cleanup_test_data` dans `tests/conftest.py`. Il utilise `TestDataManager` (`tests/utils/test_data_cleanup.py`) qui :

1. Identifie les donnees de test par patterns de noms
2. Exclut les utilisateurs permanents de toute suppression
3. Protege les attempts/progress des utilisateurs permanents meme sur des exercices de test
4. Supprime dans l'ordre FK : challenge_attempts ‚Üí attempts ‚Üí recommendations ‚Üí progress ‚Üí challenges ‚Üí exercises ‚Üí users

### Nettoyage one-shot (production)

Si des donnees de test ont persiste en production, utiliser le script de nettoyage :

```bash
# Mode dry-run (affiche sans supprimer)
python scripts/cleanup_test_data_production.py

# Mode execution (supprime reellement, demande confirmation)
python scripts/cleanup_test_data_production.py --execute
```

Ce script protege les memes utilisateurs permanents et respecte le meme ordre FK.

### Regles de securite pour les tests

1. **JAMAIS** de `db_session.query(Model).delete()` sans `.filter()` - utiliser toujours un filtre sur les patterns de test
2. **JAMAIS** d'operations sur la table `progress` ou `attempts` sans filtrer par `user_id` de test
3. **TOUJOURS** utiliser `unique_username()` / `unique_email()` pour generer des noms uniques
4. **TOUJOURS** commiter via la session de test si possible, pour que le rollback de fixture fonctionne
5. Si le test doit `commit()`, s'assurer que le `TestDataManager` pourra identifier les donnees creees

---

## üìù MODIFICATIONS RECENTES {#modifications-recentes}

### 22/02/2026 ‚Äì Mypy CI, types critiques (audit backend 5.2)

| Domaine | Modification |
|---------|---------------|
| **CI lint** | mypy ajout√© au job lint : `mypy app/ server/ --ignore-missing-imports` |
| **Types critiques** | adapter.list_active(limit, offset) Optional[int], error_handler.create_error_response(include_details) Optional[bool], pyproject overrides no-any-return pour modules critiques |
| **R√©f√©rence** | [AUDIT_BACKEND_INDUSTRIALISATION_2026-02.md](../03-PROJECT/AUDIT_BACKEND_INDUSTRIALISATION_2026-02.md) ¬ß 5.2 |

### 22/02/2026 ‚Äì Refactor CI ObiWan, couverture ExerciseService

| Domaine | Modification |
|---------|---------------|
| **CI** | Initialisation DB : sch√©ma uniquement (`create_tables`), suppression du seed global ObiWan. Tests isol√©s via fixtures. |
| **ExerciseService** | 3 tests unitaires pour `submit_answer_result` : r√©ponse correcte, incorrecte, exercice inexistant (zone critique P2). |
| **Scripts locaux** | `check_local_db.py`, `test_backend_local.py` : variable `SKIP_SEED=true` pour sch√©ma seul (align√© CI). Par d√©faut : sch√©ma + seed. |
| **test_challenge_service_integration** | Fix flaky : filtre `LogicChallengeType.SEQUENCE.value`, titre unique, `limit=100` pour `list_challenges`. |

### 26/02/2026 ‚Äì Refactoring auth service, tests unitaires

| Domaine | Modification |
|---------|--------------|
| **auth_handlers** | `verify_email` et `api_reset_password` passent par `AuthService.verify_email_token`, `AuthService.reset_password_with_token` ‚Äî plus d'acc√®s DB direct |
| **user_handlers** | R√©ponse `PUT /api/users/me` inclut `is_email_verified` |
| **Tests unitaires** | `test_auth_service.py` : `test_verify_email_token_*`, `test_reset_password_with_token_*` (succ√®s, invalid, expired, already_verified) |
| **Tests API** | `test_auth_flow.py` : `test_verify_email_success`, `test_verify_email_invalid_token` ; `test_user_endpoints.py` : r√©gression `is_email_verified` sur mise √† jour profil |
| **Documentation** | `AUTH_FLOW.md` : mention AuthService ; [INVENTAIRE_HANDLERS_DB_DIRECTE](../03-PROJECT/AUDITS_ET_RAPPORTS_ARCHIVES/RAPPORTS_TEMPORAIRES/INVENTAIRE_HANDLERS_DB_DIRECTE.md) : auth refactor√© ; `CHANGELOG.md` 2.2.2-alpha.1 |

### 15/02/2026 ‚Äì Quality gates CI, test unicit√© routes

| Domaine | Modification |
|---------|---------------|
| **Test unicit√© routes** | `tests/unit/test_routes_uniqueness.py` : d√©tecte les collisions (method, path) dans `get_routes()`. √âchoue si deux routes partagent le m√™me couple. |
| **CI backend** | S√©paration unit (tests/unit/) et integration (tests/api/, integration/, functional/). `coverage combine` pour agr√©ger la couverture. |
| **CI frontend** | `npm run lint` (ESLint) ajout√© avant tests et build. |

### 20/02/2026 ‚Äì Nettoyage skips, suppression delete_exercise, nouveaux tests

| Domaine | Modification |
|---------|--------------|
| **Suppression DELETE /api/exercises/{id}** | Handler et route supprim√©s (pas de frontend, archivage pr√©vu dans l'admin). Fichiers : `test_deletion_endpoints.py` supprim√©, `test_exercise_endpoints`, `test_role_permissions` mis √† jour. |
| **Suppression tests obsol√®tes** | `test_create_logic_challenge` (POST challenges non impl√©ment√©), `test_cli.py` (mathakine_cli archiv√©), `test_conditional_test_based_on_db_engine` (SQLite non utilis√©). |
| **R√©activation skips** | `test_refresh_token` (auth_flow), `test_refresh_token_from_cookie_only` (auth_no_fallback), `test_sse_multiple_connections` (asyncio.gather). |
| **test_challenges_flow** | `test_generate_ai_challenge_stream` : `skipif(not OPENAI_API_KEY)` pour ex√©cution quand cl√© dispo. |
| **test_db_init_service** | Suppression 2 skips schema (exercises/attempts integration). Nouveau `test_create_test_exercises_and_attempts_with_mocked_session`. |
| **Nouveaux tests base** | `test_base_endpoints.py` : `test_health_endpoint`, `test_robots_txt`, `test_csrf_token_endpoint`. |
| **Fixtures auth** | Extraction refresh_token depuis Set-Cookie pour tests HTTP (cookie Secure non transmis). |

### 15/02/2026 ‚Äì Priorit√©s couverture + tests r√©gression

| Domaine | Modification |
|---------|--------------|
| **Priorit√©s couverture** | Nouvelle section ¬ß Priorit√©s de couverture frontend : utils/validations (P1), r√©gression bugs (P2), hooks (P3). √âviter : pages enti√®res, composants purement pr√©sentationnels. |
| **safeValidateUserStats** | 11 tests ajout√©s (`__tests__/unit/lib/validations/dashboard.test.ts`) : null/undefined, level (objet/number), progress_over_time, exercises_by_day, exercises_by_type. |
| **Documentation** | Rappel corrections 15/02 : typage visualData (renderers), useAccessibleAnimation, validation dashboard, vitest.setup. |

### Fevrier 2026 ‚Äì Session couverture et stabilisation

| Domaine | Modification |
|---------|--------------|
| **Backend** | `test_user_exercise_flow.py` : utilise `POST /api/exercises/generate` (pas de POST /api/exercises/), parametre `answer` pour les tentatives, `GET /api/users/stats` pour les stats |
| **Frontend** | `ExerciseCard.test.tsx` : wrapper NextIntlClientProvider + QueryClientProvider, mock useCompletedItems |
| **Frontend** | `AccessibilityToolbar` : tests adaptes (ouverture menu via userEvent, role="switch"), aria-label sur les options |
| **Frontend** | `BadgeCard.test.tsx` : mocks alignes sur types Badge/UserBadge (plus de requirements, achievement_id) |
| **Next.js 16** | Migration middleware.ts ‚Üí proxy.ts (convention depreciee) |
| **CI** | Tests frontend avec coverage avant build, upload Codecov backend + frontend |
| **Dependances** | @testing-library/user-event, @vitest/coverage-v8 ajoutes |

### API exercices utiles

| Endpoint | Methode | Note |
|----------|---------|------|
| `/api/exercises/generate` | POST | Creer un exercice (exercise_type, age_group requis) |
| `/api/exercises/{id}/attempt` | POST | Soumettre une tentative (parametre `answer` ou `selected_answer`) |
| `/api/users/stats` | GET | Stats du user connecte (pas /api/users/{id}/stats) |

---

## üìö RESSOURCES

- [pytest Documentation](https://docs.pytest.org/)
- [Vitest](https://vitest.dev/)
- [Testing Library](https://testing-library.com/)
- [Playwright](https://playwright.dev/)
- [Coverage.py](https://coverage.readthedocs.io/)
- [Development Guide](DEVELOPMENT.md)

---

**Bon testing !** üß™‚úÖ

