"""
Handlers pour le chatbot utilisant OpenAI
Optimis√© avec streaming SSE, smart routing, et best practices AI modernes
"""
import json
import os

from starlette.responses import JSONResponse, StreamingResponse

from app.core.config import settings
from app.core.logging_config import get_logger

logger = get_logger(__name__)

try:
    from openai import AsyncOpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False


def _detect_complexity(message: str, conversation_history: list) -> str:
    """
    D√©tecte la complexit√© de la question pour smart routing.
    Retourne 'simple' ou 'complex' pour choisir le mod√®le appropri√©.
    
    Best practice : Utiliser gpt-4o-mini pour questions simples (co√ªt r√©duit),
    gpt-4o pour questions complexes (meilleure qualit√©).
    """
    message_lower = message.lower()
    
    # Indicateurs de complexit√©
    complex_keywords = [
        'd√©montrer', 'prouver', 'th√©or√®me', 'formule', '√©quation complexe',
        'raisonnement', 'd√©duction', 'logique avanc√©e', 'grille logique',
        'combinatoire', 'probabilit√©', 's√©quence complexe', 'pattern avanc√©',
        'r√©soudre √©tape par √©tape', 'explique en d√©tail', 'comment fonctionne'
    ]
    
    simple_keywords = [
        'combien fait', 'c\'est quoi', 'qu\'est-ce que', 'd√©finition',
        'exemple', 'calcul simple', 'addition', 'soustraction', 'multiplication',
        'division', 'aide', 'explique simplement'
    ]
    
    # Questions courtes = g√©n√©ralement simples
    if len(message.split()) <= 5:
        return 'simple'
    
    # D√©tecter mots-cl√©s complexes
    if any(keyword in message_lower for keyword in complex_keywords):
        return 'complex'
    
    # D√©tecter mots-cl√©s simples
    if any(keyword in message_lower for keyword in simple_keywords):
        return 'simple'
    
    # Par d√©faut, utiliser le mod√®le simple pour √©conomiser les co√ªts
    return 'simple'


def _estimate_age(message: str) -> str | None:
    """
    Estime l'√¢ge de l'utilisateur depuis le message.
    Am√©lioration : pourrait utiliser le profil utilisateur si disponible.
    """
    message_lower = message.lower()
    
    if any(word in message_lower for word in ['cm1', 'cm2', 'cp', 'ce1', 'ce2', 'maternelle']):
        return '5-8'
    elif any(word in message_lower for word in ['6√®me', '5√®me', 'coll√®ge', 'primaire']):
        return '9-12'
    elif any(word in message_lower for word in ['4√®me', '3√®me', 'lyc√©e', 'seconde']):
        return '13-16'
    elif any(word in message_lower for word in ['terminale', 'bac', 'universit√©']):
        return '17-20'
    
    return None


def _build_system_prompt(estimated_age: str | None = None) -> str:
    """
    Construit le prompt syst√®me optimis√© avec few-shot learning am√©lior√©.
    Best practice : Exemples concrets dans le prompt pour guider l'IA.
    """
    age_context = ""
    if estimated_age:
        age_context = f"\n\nüìä CONTEXTE UTILISATEUR : L'utilisateur a environ {estimated_age} ans. Adapte ton langage, tes exemples et ta complexit√© en cons√©quence."

    return f"""<persona>
Tu es Ma√Ætre Kine, un dro√Øde-enseignant sage, patient et un peu malicieux, sp√©cialis√© en math√©matiques et logique pour la plateforme Mathakine. Ta mission est de rendre les maths amusantes et accessibles pour tous, des jeunes Padawans (enfants) aux Chevaliers confirm√©s (adolescents et "adulescents"). Tu es un expert en **math√©logique**.
</persona>

<mission>
Ton r√¥le est d'√™tre un guide bienveillant. Tu dois engager les utilisateurs avec des d√©fis, des √©nigmes et des explications claires, en te concentrant sur le raisonnement logique qui sous-tend les math√©matiques.
</mission>

<domaines_de_predilection>
- **MATH√âLOGIQUE (Ta sp√©cialit√©)**: Propose TOUJOURS en priorit√© des d√©fis de logique, puzzles, s√©quences, et √©nigmes. C'est ta marque de fabrique.
- **Concepts Math√©matiques**: Explique simplement les fractions, la g√©om√©trie, l'alg√®bre, les pourcentages, etc.
- **Calculs**: Aide avec les op√©rations de base, mais rends-les int√©ressantes !
- **Visualisations**: N'h√©site pas √† proposer de cr√©er une image pour illustrer un concept. Dis "Je peux te faire un sch√©ma de √ßa !" et le syst√®me s'en chargera.
</domaines_de_predilection>

<strategie_conversationnelle>
1.  **Sois Flexible et Cr√©atif**: Si un utilisateur pose une question qui semble hors-sujet (ex: "Quelle est la couleur du sabre de Mace Windu ?"), ne bloque pas la conversation. R√©ponds bri√®vement et pivote intelligemment vers les maths.
    *   *Exemple de pivot*: "Excellente question de culture galactique ! Son sabre est violet. Savais-tu que la trajectoire d'un sabre laser peut √™tre d√©crite par des √©quations math√©matiques ? √áa t'int√©resse que je t'explique ?"
2.  **Transforme les Questions**: Change les questions non-math√©matiques en probl√®mes.
    *   *Exemple*: Si on te demande "combien de temps pour aller sur Mars ?", r√©ponds : "√áa d√©pend de la vitesse ! Si un vaisseau voyage √† 40 000 km/h et que Mars est √† 80 millions de km, combien de jours durerait le voyage ? Faisons le calcul ensemble !"
3.  **Redirection Douce**: Si la question est vraiment trop √©loign√©e, redirige avec humour et bienveillance.
    *   *Exemple*: "Ah, mes circuits sont sp√©cialis√©s en nombres et en logique, pas en politique galactique ! Mais je peux te proposer une √©nigme pour te changer les id√©es. Pr√™t(e) ?"
</strategie_conversationnelle>

<style_de_communication_adapte_tsa_tdah>
- **Clart√© et Structure**: Langage simple, phrases courtes. Utilise des listes √† puces et du gras pour structurer l'information.
- **Ton**: Toujours bienveillant, patient et tr√®s encourageant. C√©l√®bre chaque effort !
- **Exemples Concrets**: Utilise des analogies de l'univers Star Wars ou du quotidien.
- **Adaptation √† l'√¢ge**:
    - *Padawan (5-12 ans)*: "Imagine que tu as 3 Wookiees et que 2 autres se joignent √† la f√™te. Combien de Wookiees en tout ?"
    - *Chevalier (13-20 ans)*: "Analysons la probabilit√© qu'un tir de blaster atteigne sa cible en fonction de la distance. On peut utiliser une fonction..."
</style_de_communication_adapte_tsa_tdah>

<regles_critiques>
1.  **Math√©logique d'Abord**: C'est ta priorit√© absolue.
2.  **Exercices Complets**: Quand tu donnes un exercice, il doit √™tre complet et r√©solvable (√©nonc√©, r√®gles, question).
3.  **Pas de Fausses Images**: Ne g√©n√®re JAMAIS de syntaxe Markdown pour les images (`![...](...)`). Propose simplement d'en cr√©er une.
</regles_critiques>

{age_context}
"""


async def chat_api(request):
    """
    Endpoint API pour le chatbot
    
    Utilise OpenAI pour r√©pondre aux questions sur Mathakine
    """
    try:
        # V√©rifier que OpenAI est disponible
        if not OPENAI_AVAILABLE:
            return JSONResponse(
                {"error": "OpenAI non disponible"},
                status_code=503
            )
        
        # V√©rifier que la cl√© API est configur√©e
        if not settings.OPENAI_API_KEY:
            return JSONResponse(
                {"error": "Cl√© API OpenAI non configur√©e"},
                status_code=503
            )
        
        # R√©cup√©rer les donn√©es de la requ√™te
        data = await request.json()
        message = data.get('message', '')
        conversation_history = data.get('conversation_history', [])
        
        if not message:
            return JSONResponse(
                {"error": "Message requis"},
                status_code=400
            )
        
        # Cr√©er le client OpenAI
        client = AsyncOpenAI(api_key=settings.OPENAI_API_KEY)
        
        # D√©tecter si la demande concerne une image math√©matique
        image_keywords = ['image', 'dessine', 'dessin', 'sch√©ma', 'diagramme', 'figure', 'graphique', 'visualise', 'montre', 'cr√©er', 'g√©n√®re', 'fais', 'montre-moi', 'affiche']
        math_image_keywords = ['g√©om√©trie', 'triangle', 'cercle', 'carr√©', 'rectangle', 'forme', 'angle', 'fraction', 'graphique', 'courbe', 'polygone', 'losange', 'trap√®ze', 'cercle', 'ovale', 'ligne', 'point', 'segment', 'exercice', 'probl√®me']
        
        is_image_request = any(keyword in message.lower() for keyword in image_keywords)
        is_math_related = any(keyword in message.lower() for keyword in math_image_keywords) or any(
            keyword in message.lower() for keyword in ['math', 'math√©matique', 'calcul', 'nombre', '√©quation', 'exercice', 'probl√®me']
        )
        
        # Si demande d'image ET math√©matique, g√©n√©rer une image avec DALL-E
        # MAIS continuer avec la r√©ponse texte compl√®te pour avoir l'exercice r√©solvable
        if is_image_request and is_math_related:
            try:
                # Construire un prompt optimis√© pour DALL-E (style √©ducatif, adapt√© enfants)
                dalle_prompt = f"""Image √©ducative math√©matique pour enfants de 5 √† 20 ans : {message}. 
Style simple, clair, color√©, adapt√© aux enfants. √âl√©ments visuels math√©matiques uniquement. 
Pas de texte complexe, formes g√©om√©triques simples, couleurs vives et contrast√©es."""
                
                # G√©n√©rer une image avec DALL-E 3
                image_response = await client.images.generate(
                    model="dall-e-3",
                    prompt=dalle_prompt,
                    size="1024x1024",
                    quality="standard",
                    n=1,
                )
                
                image_url = image_response.data[0].url
                # Ne pas retourner imm√©diatement - continuer pour g√©n√©rer l'exercice complet
                # L'image sera ajout√©e √† la r√©ponse finale
            except Exception as dalle_generation_error:
                # Si erreur de g√©n√©ration d'image, continuer avec la r√©ponse texte normale
                logger.error(f"Erreur g√©n√©ration image DALL-E: {str(dalle_generation_error)}")
                image_url = None
        else:
            image_url = None
        
        # D√©tecter la complexit√© pour smart routing
        complexity = _detect_complexity(message, conversation_history)
        
        # Smart routing : choisir le mod√®le selon la complexit√©
        # Best practice : gpt-4o-mini pour questions simples (co√ªt r√©duit), gpt-4o pour complexes (qualit√©)
        model = "gpt-4o-mini" if complexity == 'simple' else "gpt-4o"
        
        # D√©tecter l'√¢ge pour personnalisation
        estimated_age = _estimate_age(message)
        
        # Construire le prompt syst√®me optimis√© avec few-shot learning
        system_prompt = _build_system_prompt(estimated_age)

        # Construire les messages pour OpenAI
        messages = [
            {"role": "system", "content": system_prompt}
        ]
        
        # Ajouter l'historique de conversation (limit√© aux 5 derniers messages)
        for msg in conversation_history[-5:]:
            messages.append({
                "role": msg.get("role", "user"),
                "content": msg.get("content", "")
            })
        
        # Ajouter le message actuel
        messages.append({
            "role": "user",
            "content": message
        })
        
        # Appeler OpenAI avec param√®tres optimis√©s selon la complexit√©
        # Best practice : Param√®tres adapt√©s selon le mod√®le et la complexit√©
        # Augment√© max_tokens pour permettre des exercices complets et r√©solvables
        temperature = 0.4 if complexity == 'simple' else 0.6  # Plus pr√©visible pour questions simples
        max_tokens = 500 if complexity == 'complex' else 400  # Augment√© pour exercices complets
        
        response = await client.chat.completions.create(
            model=model,  # Smart routing : mod√®le choisi selon complexit√©
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens,
            top_p=0.9,
            frequency_penalty=0.3,
            presence_penalty=0.1,
        )
        
        # Extraire la r√©ponse
        assistant_message = response.choices[0].message.content
        
        # Nettoyer les placeholders d'images Markdown (best practice : √©viter les placeholders)
        # Supprimer les patterns comme ![texte](url) ou ![texte](placeholder)
        import re

        # Supprimer les images Markdown avec placeholders ou URLs suspectes
        assistant_message = re.sub(
            r'!\[([^\]]*)\]\([^)]*(?:placeholder|via\.placeholder|example\.com|example\.org)[^)]*\)',
            r'\1',  # Remplacer par juste le texte alternatif
            assistant_message,
            flags=re.IGNORECASE
        )
        # Supprimer aussi les images Markdown g√©n√©riques sans URL valide
        assistant_message = re.sub(
            r'!\[([^\]]*)\]\([^)]*\)',
            lambda m: m.group(1) if 'http' not in m.group(0).lower() else m.group(0),
            assistant_message
        )
        
        # Retourner la r√©ponse avec l'image si elle a √©t√© g√©n√©r√©e
        response_data = {
            "response": assistant_message,
            "model_used": model,  # Debug : indiquer quel mod√®le a √©t√© utilis√©
            "complexity": complexity  # Debug : indiquer la complexit√© d√©tect√©e
        }
        
        # Ajouter l'URL de l'image si elle a √©t√© g√©n√©r√©e
        if image_url:
            response_data["image_url"] = image_url
            response_data["type"] = "image"
        
        return JSONResponse(response_data)
        
    except Exception as chat_api_error:
        logger.error(f"Erreur dans chat_api: {str(chat_api_error)}")
        import traceback
        traceback.print_exc()
        return JSONResponse(
            {"error": f"Erreur lors de la g√©n√©ration de la r√©ponse: {str(chat_api_error)}"},
            status_code=500
        )


async def chat_api_stream(request):
    """
    Endpoint API pour le chatbot avec streaming SSE.
    
    Best practice : Streaming pour meilleure UX - l'utilisateur voit la r√©ponse
    appara√Ætre progressivement au lieu d'attendre la r√©ponse compl√®te.
    
    R√©duit la perception du temps d'attente et am√©liore l'engagement.
    """
    try:
        # V√©rifier que OpenAI est disponible
        if not OPENAI_AVAILABLE:
            async def error_generator():
                yield f"data: {json.dumps({'type': 'error', 'message': 'OpenAI non disponible'})}\n\n"
            
            return StreamingResponse(
                error_generator(),
                media_type="text/event-stream",
                headers={
                    "Cache-Control": "no-cache",
                    "Connection": "keep-alive",
                }
            )
        
        # V√©rifier que la cl√© API est configur√©e
        if not settings.OPENAI_API_KEY:
            async def error_generator():
                yield f"data: {json.dumps({'type': 'error', 'message': 'Cl√© API OpenAI non configur√©e'})}\n\n"
            
            return StreamingResponse(
                error_generator(),
                media_type="text/event-stream",
                headers={
                    "Cache-Control": "no-cache",
                    "Connection": "keep-alive",
                }
            )
        
        # R√©cup√©rer les donn√©es de la requ√™te
        data = await request.json()
        message = data.get('message', '')
        conversation_history = data.get('conversation_history', [])
        use_streaming = data.get('stream', True)  # Streaming par d√©faut
        
        if not message:
            async def error_generator():
                yield f"data: {json.dumps({'type': 'error', 'message': 'Message requis'})}\n\n"
            
            return StreamingResponse(
                error_generator(),
                media_type="text/event-stream",
                headers={
                    "Cache-Control": "no-cache",
                    "Connection": "keep-alive",
                }
            )
        
        # Cr√©er le client OpenAI
        client = AsyncOpenAI(api_key=settings.OPENAI_API_KEY)
        
        # D√©tecter si la demande concerne une image math√©matique
        image_keywords = ['image', 'dessine', 'dessin', 'sch√©ma', 'diagramme', 'figure', 'graphique', 'visualise', 'montre', 'cr√©er', 'g√©n√®re', 'fais', 'montre-moi', 'affiche']
        math_image_keywords = ['g√©om√©trie', 'triangle', 'cercle', 'carr√©', 'rectangle', 'forme', 'angle', 'fraction', 'graphique', 'courbe', 'polygone', 'losange', 'trap√®ze', 'cercle', 'ovale', 'ligne', 'point', 'segment', 'exercice', 'probl√®me']
        
        is_image_request = any(keyword in message.lower() for keyword in image_keywords)
        is_math_related = any(keyword in message.lower() for keyword in math_image_keywords) or any(
            keyword in message.lower() for keyword in ['math', 'math√©matique', 'calcul', 'nombre', '√©quation', 'exercice', 'probl√®me']
        )
        
        # Si demande d'image ET math√©matique, g√©n√©rer une image avec DALL-E
        # MAIS continuer avec la r√©ponse texte compl√®te pour avoir l'exercice r√©solvable
        image_url = None
        if is_image_request and is_math_related:
            try:
                dalle_prompt = f"""Image √©ducative math√©matique pour enfants de 5 √† 20 ans : {message}. 
Style simple, clair, color√©, adapt√© aux enfants. √âl√©ments visuels math√©matiques uniquement. 
Pas de texte complexe, formes g√©om√©triques simples, couleurs vives et contrast√©es."""
                
                image_response = await client.images.generate(
                    model="dall-e-3",
                    prompt=dalle_prompt,
                    size="1024x1024",
                    quality="standard",
                    n=1,
                )
                
                image_url = image_response.data[0].url
                # Ne pas retourner imm√©diatement - continuer pour g√©n√©rer l'exercice complet
                # L'image sera envoy√©e dans le stream avec la r√©ponse texte compl√®te
            except Exception as dalle_stream_error:
                logger.error(f"Erreur g√©n√©ration image DALL-E: {str(dalle_stream_error)}")
                # Continuer avec le traitement texte normal
                image_url = None
        
        # D√©tecter la complexit√© pour smart routing
        complexity = _detect_complexity(message, conversation_history)
        model = "gpt-4o-mini" if complexity == 'simple' else "gpt-4o"
        
        # D√©tecter l'√¢ge pour personnalisation
        estimated_age = _estimate_age(message)
        
        # Construire le prompt syst√®me optimis√©
        system_prompt = _build_system_prompt(estimated_age)
        
        # Construire les messages pour OpenAI
        messages = [
            {"role": "system", "content": system_prompt}
        ]
        
        # Ajouter l'historique de conversation (limit√© aux 5 derniers messages)
        # Best practice : Limiter l'historique pour √©viter d√©passement de contexte
        for msg in conversation_history[-5:]:
            messages.append({
                "role": msg.get("role", "user"),
                "content": msg.get("content", "")
            })
        
        # Ajouter le message actuel
        messages.append({
            "role": "user",
            "content": message
        })
        
        # Param√®tres optimis√©s selon la complexit√©
        # Augment√© max_tokens pour permettre des exercices complets et r√©solvables
        temperature = 0.4 if complexity == 'simple' else 0.6
        max_tokens = 500 if complexity == 'complex' else 400  # Augment√© pour exercices complets
        
        async def generate_stream():
            try:
                # Si une image a √©t√© g√©n√©r√©e, l'envoyer en premier
                if image_url:
                    yield f"data: {json.dumps({'type': 'image', 'url': image_url})}\n\n"
                
                # Envoyer un message de d√©marrage
                yield f"data: {json.dumps({'type': 'status', 'message': 'R√©flexion en cours...'})}\n\n"
                
                # Cr√©er le stream OpenAI
                stream = await client.chat.completions.create(
                    model=model,
                    messages=messages,
                    stream=True,  # Activer le streaming
                    temperature=temperature,
                    max_tokens=max_tokens,
                    top_p=0.9,
                    frequency_penalty=0.3,
                    presence_penalty=0.1,
                )
                
                # Stream chaque chunk de la r√©ponse
                full_response = ""
                async for chunk in stream:
                    if chunk.choices and chunk.choices[0].delta.content:
                        content = chunk.choices[0].delta.content
                        full_response += content
                        # Envoyer chaque chunk au client pour affichage progressif
                        yield f"data: {json.dumps({'type': 'chunk', 'content': content})}\n\n"
                
                # Nettoyer les placeholders d'images Markdown dans la r√©ponse compl√®te
                import re
                cleaned_response = re.sub(
                    r'!\[([^\]]*)\]\([^)]*(?:placeholder|via\.placeholder|example\.com|example\.org)[^)]*\)',
                    r'\1',
                    full_response,
                    flags=re.IGNORECASE
                )
                cleaned_response = re.sub(
                    r'!\[([^\]]*)\]\([^)]*\)',
                    lambda m: m.group(1) if 'http' not in m.group(0).lower() else m.group(0),
                    cleaned_response
                )
                
                # Si la r√©ponse a √©t√© nettoy√©e, envoyer un chunk de correction si n√©cessaire
                if cleaned_response != full_response:
                    # La r√©ponse a d√©j√† √©t√© envoy√©e chunk par chunk, donc on ne peut pas la modifier
                    # Mais on peut envoyer un message de fin avec indication
                    pass
                
                # Envoyer un message de fin avec m√©tadonn√©es
                yield f"data: {json.dumps({'type': 'done', 'model_used': model, 'complexity': complexity})}\n\n"
                
            except Exception as stream_generation_error:
                logger.error(f"Erreur dans generate_stream: {str(stream_generation_error)}")
                yield f"data: {json.dumps({'type': 'error', 'message': f'Erreur lors de la g√©n√©ration: {str(stream_generation_error)}'})}\n\n"
        
        return StreamingResponse(
            generate_stream(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no",  # Important pour Nginx
            }
        )
        
    except Exception as chat_stream_error:
        logger.error(f"Erreur dans chat_api_stream: {str(chat_stream_error)}")
        import traceback
        traceback.print_exc()
        
        async def error_generator():
            yield f"data: {json.dumps({'type': 'error', 'message': f'Erreur lors de la g√©n√©ration: {str(chat_stream_error)}'})}\n\n"
        
        return StreamingResponse(
            error_generator(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
            }
        )

